{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.graph_objects as go\n",
    "from Plot3D import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Models\n",
    "Example usage of the Camera object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data: sphere \n",
    "px, py, pz = 4.5, 1, 1\n",
    "data1 = np.array([[np.cos(theta)*np.sin(phi)+px, np.sin(theta)*np.sin(phi)+py, np.cos(phi)+pz] \n",
    "                 for theta in np.linspace(0, 2*np.pi, 10)\n",
    "                 for phi in np.linspace(0, np.pi, 10)])\n",
    "# example data: cube\n",
    "px, py, pz = 4, -2, 1\n",
    "t_ = np.linspace(-0.5, 0.5, 5)\n",
    "x_, y_, z_ = t_ + px, t_ + py, t_ + pz\n",
    "x, y, z = np.meshgrid(x_, y_, z_, indexing='ij')\n",
    "data2 = np.c_[x.ravel(), y.ravel(), z.ravel()]\n",
    "\n",
    "# create a point cloud object\n",
    "pts = PointCloud()\n",
    "pts.add_data([data1, 'red'])\n",
    "pts.add_data([data2, 'blue'])\n",
    "\n",
    "# create two cameras\n",
    "camera1 = Camera(Ry(np.pi/2)@Rz(-np.pi/2)@Ry(np.pi/4), np.array([2, 3, 1]), \"Cam1\")\n",
    "camera2 = Camera(Ry(np.pi/2)@Rz(-np.pi/2)@Ry(-np.pi/9), np.array([1, -2, 1]), \"Cam2\")\n",
    "\n",
    "camera1.capture(pts)\n",
    "camera2.capture(pts)\n",
    "\n",
    "# add some other objects\n",
    "line1 = Segment(camera1.center, camera2.center, color='black')\n",
    "pt1 = Point(camera1.center, color='red')\n",
    "\n",
    "FIG = Show([camera1, camera2, pts, line1, pt1], world=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Save the 3D plot as png file just for demonstration purpose on GitHub\n",
    "#FIG.write_image(\"fig1.png\")\n",
    "#%run display_image.py\n",
    "# -----------------------------\n",
    "\n",
    "camera1.show_image()\n",
    "camera2.show_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera anatomy \n",
    "### Finding the camera center\n",
    "Camera projection matrix: $P=KR[I|-C]$ <br>\n",
    "Method 1: Camera center $C$ is in the null space of $P$ such that $PC=0$. <br>\n",
    "Method 2: Directly derive the solution from the projection matrix. <br>\n",
    "Method 3: Using the following formula<br>\n",
    "$x = det([p_2, p_3, p_4]), y = -det([p_1, p_3, p_4]), \\\\z = det([p_1, p_2, p_4]), t = -det([p_1, p_2, p_3])$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "# method 1\n",
    "def find_center1(P):\n",
    "    homo_c = scipy.linalg.null_space(P).ravel()\n",
    "    return homo2eucl(homo_c)\n",
    "\n",
    "# method 2\n",
    "def find_center2(P):\n",
    "    M = P[:, :3]\n",
    "    m = P[:, -1]\n",
    "    center = -np.linalg.inv(M) @ m\n",
    "    return center\n",
    "\n",
    "# method 3\n",
    "def find_center3(P):\n",
    "    x = np.linalg.det(np.stack([camera1.P[:, 1], camera1.P[:, 2], camera1.P[:, 3]]))\n",
    "    y = -np.linalg.det(np.stack([camera1.P[:, 0], camera1.P[:, 2], camera1.P[:, 3]]))\n",
    "    z = np.linalg.det(np.stack([camera1.P[:, 0], camera1.P[:, 1], camera1.P[:, 3]]))\n",
    "    t = -np.linalg.det(np.stack([camera1.P[:, 0], camera1.P[:, 1], camera1.P[:, 2]]))\n",
    "    homo_c = np.array([x, y, z, t])\n",
    "    return homo2eucl(homo_c)\n",
    "\n",
    "print(\"Method 1 :\", np.allclose(find_center1(camera1.P), camera1.center))\n",
    "print(\"Method 2 :\", np.allclose(find_center2(camera1.P), camera1.center))\n",
    "print(\"Method 3 :\", np.allclose(find_center3(camera1.P), camera1.center))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the camera orientation and internal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(A):\n",
    "    # Gram-Schmidt only works for full rank matrix\n",
    "    # if not full rank, use numpy qr decomposition\n",
    "    if np.linalg.matrix_rank(A) < A.shape[1]:\n",
    "        print(\"call numpy qr\")\n",
    "        Q, _ = np.linalg.qr(A)\n",
    "        return Q\n",
    "    Q = []\n",
    "    for i in range(A.shape[1]):\n",
    "        u = A[:, i]\n",
    "        for q in Q:\n",
    "            u = u - (q @ A[:, i]) * q / (q @ q)\n",
    "        Q.append(u / np.linalg.norm(u))\n",
    "    return np.array(Q).T\n",
    "\n",
    "def qr(A):\n",
    "    Q = gram_schmidt(A)\n",
    "    R = Q.T @ A \n",
    "    return Q, R \n",
    "\n",
    "def rq(A):\n",
    "    Q = gram_schmidt(A.T[:, ::-1])[:, ::-1].T\n",
    "    R = A @ Q.T\n",
    "    return R, Q\n",
    "\n",
    "K, R = rq(camera1.P[:, :-1])\n",
    "print(\"Camera calibration matrix (K) :\", np.allclose(K, camera1.K))\n",
    "print(\"Camera pose (R) :\", np.allclose(R, camera1.R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of the Camera Matrix P\n",
    "Assume we have a number of point correspondences $\\mathbf{X_i} \\leftrightarrow \\left( {\\begin{array}{c} x_i \\\\ y_i \\\\ w_i\\end{array}} \\right)$\n",
    "$$\n",
    "\\left[ {\\begin{array}{ccc}\n",
    "    0^T & -w_i\\mathbf{X}_i^T & y_i\\mathbf{X}_i^T \\\\\n",
    "    w_i\\mathbf{X}_i^T & 0^T & -x_i\\mathbf{X}_i^T \\\\\n",
    "     & . & \\\\\n",
    "     & . & \\\\\n",
    "     & . & \\\\\n",
    "\\end{array}}\\right]\n",
    "\\left( {\\begin{array}{c} P_1 \\\\ P_2 \\\\ P_3 \\end{array}}\\right) = 0\n",
    "$$\n",
    "\n",
    "### Solve $Ap = 0$ subject to  $\\lVert p \\rVert = 1$ <br>\n",
    "When the system is over-determined, the problem becomes minimizing $\\lVert Ap \\rVert$ subject to  $\\lVert p \\rVert = 1$. <br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&L(p, \\lambda) = p^T A^T A p + \\lambda (1 - p^T p) \\\\\n",
    "&\\frac{\\partial L(p, \\lambda)}{\\partial p} = 2 A^T A p - 2 \\lambda p = 0 \\\\\n",
    "&\\Rightarrow A^T A p = \\lambda p \\\\\n",
    "&\\Rightarrow p = \\text{Eigenvector of } A^T A \\\\\n",
    "&\\Rightarrow p \\in \\{ v_i| [v_1, v_2, ...]  = V \\} \\ \\text{, where}\\ A = U \\Sigma V^T \n",
    "\\end{aligned}\n",
    "$$\n",
    "Now we know that $p$ is a singular vector of $A$. Now evaluate the loss function\n",
    "$$ \n",
    "\\lVert Ap \\rVert = \\lVert Av_i \\rVert=\\sqrt{(Av_i)^T Av_i} = \\sqrt{(\\sigma_i u_i)^T \\sigma_i u_i} = \\sqrt{\\sigma_i^2} = \\sigma_i \n",
    "$$\n",
    "Thus, to minimize this term, we can just choose $p$ to be the singular vector of the smallest singular value of $A$. $\\ \\ \\ \\ \\square$\n",
    "<br><br>\n",
    "Alternative solution can be minimizing $\\frac{\\lVert Ap\\rVert}{\\lVert p \\rVert}$ directly with no constraint, which leads to the same result. The derivation is omitted here, but can be found in Gil Strang's Linear Algebra textbook.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = eucl2homo(camera1.world_pts)\n",
    "x = eucl2homo(camera1.image_pts)\n",
    "\n",
    "def find_P(X, x):\n",
    "    A = np.zeros((X.shape[0], 2*12))\n",
    "    for i in range(A.shape[0]):\n",
    "        A[i, 4:8] = -x[i, 2] * X[i, :]\n",
    "        A[i, 8:12] = x[i, 1] * X[i, :]\n",
    "        A[i, 12:16] = x[i, 2] * X[i, :]\n",
    "        A[i, 20:24] = -x[i, 0] * X[i, :]\n",
    "    A = A.reshape(int(A.shape[0] * 2), int(A.shape[1] / 2))\n",
    "    U, sig, Vt = np.linalg.svd(A)\n",
    "    Pi = Vt[-1, :]\n",
    "\n",
    "    P = np.stack([Pi[0:4], Pi[4:8], Pi[8:12]])\n",
    "    P /= P[-1, -1]\n",
    "    return P\n",
    "\n",
    "def compareP(P_cam, P_estimate, X, x):\n",
    "    normalize = lambda P: P/P[-1, -1]\n",
    "    print(\"Compare P1 and P2 after rescaled :\", np.allclose(normalize(P_cam), normalize(P_estimate)))\n",
    "    x_estimate = X @ P_estimate.T\n",
    "    x = homo2eucl(x)\n",
    "    x_estimate = homo2eucl(x_estimate)\n",
    "    print(\"Compare P1 and P2 by point transformation result:\", np.allclose(x, x_estimate))\n",
    "\n",
    "P = find_P(X, x)\n",
    "compareP(camera1.P, P, X, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Pseudoinverse \n",
    "Pseudoinverse is part of the solution of $Ax=b$. When the system is over- or underdetermined, $\\hat{x}=A^{+} b$, where $A^{+}$ is the pseudoinverse of $A$.\n",
    "\n",
    "### Case 1: Underdetermined system $Ax=b$ <br>\n",
    "Since $b \\in C(A)$, x has infinite solutions. Thus, the problem becomes minimizing $\\lVert x \\rVert$ s.t. $Ax=b$.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "minimize & \\ \\lVert x \\rVert s.t. Ax=b \\\\\n",
    "= minimize & \\ \\frac{x^T x}{2} \\ s.t. \\ Ax = b \\\\\n",
    "\\Rightarrow L(x, \\lambda) &= \\frac{x^T x}{2} + \\lambda^T(b-Ax) \\\\\n",
    "\\Rightarrow \\frac{\\partial L(x, \\lambda)}{\\partial x} &= x - A^T \\lambda \\Rightarrow x = A^T \\lambda \\\\\n",
    "\\Rightarrow L(\\lambda) &= \\frac{1}{2} \\lambda^T A A^T \\lambda + \\lambda^T b- \\lambda^T A A^T \\lambda \\\\\n",
    "&= -\\frac{1}{2} \\lambda^T A A^T \\lambda + \\lambda^T b \\\\\n",
    "\\frac{\\partial L(\\lambda)}{\\partial \\lambda} &= -A A^T \\lambda + b = 0 \\\\\n",
    "\\Rightarrow b &= A A^T \\lambda \\\\\n",
    "\\Rightarrow \\lambda &= (A A^T)^{-1} b  \\\\\n",
    "\\Rightarrow \\hat{x} &= A^T(A A^T)^{-1} b \n",
    "\\end{aligned}\n",
    "$$\n",
    "(Note that $A$ : $m\\times n$, m<n. Thus, $A A^T$ is a full rank matrix)\n",
    "\n",
    "To establish a connection with SVD, let's consider, without loss of generality, matrix $A$ as a $3\\times4$ matrix, identical to the camera projection matrix and<br>\n",
    "$\n",
    "\\Sigma_{3\\times3}=\n",
    "\\left[ {\\begin{array}{ccc}\n",
    "    \\sigma_1 &  &  \\\\\n",
    "    & \\sigma_2 &  \\\\\n",
    "     &  & \\sigma_3 \\\\\n",
    "\\end{array}}\\right], \\\n",
    "\\Sigma_{3\\times4}=\n",
    "\\left[ {\\begin{array}{ccc}\n",
    "    \\sigma_1 &  & & 0 \\\\\n",
    "    & \\sigma_2 & & 0 \\\\\n",
    "     &  & \\sigma_3 & 0 \\\\\n",
    "\\end{array}}\\right], \\\n",
    "\\Sigma_{4\\times3}=\n",
    "\\left[ {\\begin{array}{ccc}\n",
    "    \\sigma_1 &  &  \\\\\n",
    "    & \\sigma_2 &  \\\\\n",
    "     &  & \\sigma_3 \\\\\n",
    "    0 &0 & 0\\\\\n",
    "\\end{array}}\\right], \\\n",
    "\\Sigma_{4\\times3}^{-1}=\n",
    "\\left[ {\\begin{array}{ccc}\n",
    "    \\sigma_1^{-1} &  &  \\\\\n",
    "    & \\sigma_2^{-1} &  \\\\\n",
    "     &  & \\sigma_3^{-1} \\\\\n",
    "    0 &0 & 0\\\\\n",
    "\\end{array}}\\right], \\\n",
    "U = \\left[ u_1 \\ u_2 \\ u_3\\right], \\\n",
    "V = \\left[ v_1 \\ v_2 \\ v_3 \\ v_4\\right], \\\n",
    "V_{4\\times3} = \\left[ v_1 \\ v_2 \\ v_3\\right]\n",
    "$\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "A &= U \\Sigma_{3\\times 4} V^T \\\\\n",
    "A^T &= V \\Sigma_{3\\times 4}^T U^T \\\\\n",
    "A A^T &= U \\Sigma_{3\\times 4} \\Sigma_{3\\times 4}^T U^T \\\\\n",
    "&= U \\Sigma_{3\\times 3}^2 U^T \\\\ \\\\\n",
    "A^T(A A^T)^{-1} &= V \\Sigma_{3\\times 4}^T U^T U (\\Sigma_{3\\times 3}^2)^{-1} U^T \\\\\n",
    "&= V \\Sigma_{4\\times 3}^{-1} U^T \\\\\n",
    "&= V_{4 \\times 3} \\Sigma_{3 \\times 3}^{-1} U^T \\\\\n",
    "&= A^{+} \\\\\n",
    "\\\\\n",
    "\\Rightarrow \\hat{x} &= A^{+} b  \\ \\ \\ \\ \\square\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "### Case 2: Overdetermined system $Ax=b$ <br>\n",
    "When the system is overdetermined, the problem becomes just minimizing $(b - Ax)^T (b - Ax)$ with no constraint.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\frac{\\partial}{\\partial x} (b - Ax)^T (b - Ax) = -2A^T(b-Ax)=0 \\\\\n",
    "&\\Rightarrow A^T A x = A^T b \\\\\n",
    "&\\Rightarrow x = (A^T A)^{-1} A^T b \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In a similar manner,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A^T A &= V \\Sigma_{m\\times n}^T U^T U \\Sigma_{m\\times n} V^T \\\\\n",
    "&= V \\Sigma_{m\\times n}^T \\Sigma_{m\\times n} V^T \\\\\n",
    "&= V \\mathbf{\\Sigma_{n\\times n}}^2 V^T \\\\\n",
    "\\\\\n",
    "(A^T A)^{-1} A^T &= V (\\Sigma_{n\\times n}^2)^{-1} V^T V \\Sigma_{m\\times n}^T U^T \\\\\n",
    "&= V (\\Sigma_{n\\times n}^2)^{-1} \\Sigma_{m\\times n}^T U^T \\\\\n",
    "&= V \\Sigma_{n\\times m}^{-1}  U^T \\\\\n",
    "&= V \\Sigma_{n\\times m}^{-1}  U^T \\\\\n",
    "&= V \\Sigma_{n\\times n}^{-1}  U_{m\\times n}^T \\\\\n",
    "&= A^{+} \\\\\n",
    "\\\\\n",
    "\\Rightarrow \\hat{x} &= A^{+} b  \\ \\ \\ \\ \\square\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The fundemental matrix $F$\n",
    "\n",
    "The epipolar line is the projection in the second image of the ray from $X$ to the center of the first camera.\n",
    "$$ \n",
    "    l^\\prime = e^\\prime \\times x^\\prime = [e^\\prime]_\\times x^\\prime\n",
    "$$\n",
    "And the fundemental matrix $F$ is a mapping that maps a 2D image point to its corresponding epipolar line on the other image plane.\n",
    "$$\n",
    "    F: x \\mapsto l^\\prime\n",
    "$$\n",
    "\n",
    "### Geometric Derivation\n",
    "The ray: $X(\\lambda) = P^+ x + \\lambda C$, where $P P^+ = I$. <br>\n",
    "$X(\\lambda=0)=P^+ x$, $X(\\lambda = \\infty) = C$. <br>\n",
    "(Note that $P^+ x \\neq X$, $P^+ x$ is a random point on the line $\\overleftrightarrow{XC}$)\n",
    "\n",
    "Then, project $P^+ x$ and C onto the second image plane by multiplying $P^\\prime$. <br>\n",
    "The epipolar line $l^\\prime$: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    l^\\prime &= P^\\prime C \\times P^\\prime P^+ x \\\\\n",
    "    &= [e^\\prime]_\\times P^\\prime P^+ x \\\\\n",
    "    &= Fx \\\\\n",
    "    \\Rightarrow F &= [e^\\prime]_\\times P^\\prime P^+ \\\\\n",
    "\\end{aligned}\n",
    "$$ \n",
    "Also,  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    l^\\prime &= Fx \\\\\n",
    "    \\Rightarrow x^{\\prime T} l^\\prime &= 0 \\\\\n",
    "    \\Rightarrow x^{\\prime T} F x &= 0 \n",
    "\\end{aligned}\n",
    "$$ \n",
    "\n",
    "### Summary of fundemental matrix properties\n",
    "- Point correspondence <br>\n",
    "$x^\\prime F x = 0$\n",
    "\n",
    "- Epipolar lines <br>\n",
    "$l\\prime = Fx$ is the epipolar line corresponding to $x$. <br>\n",
    "$l = F^T x^\\prime$ is the epipolar line corresponding to $x^\\prime$.\n",
    "\n",
    "- Epipoles <br>\n",
    "$Fe = 0$. <br>\n",
    "$F^T e^\\prime = 0$.\n",
    "\n",
    "- Computation from camera matrices $P$, $P^\\prime$ <br>\n",
    "$F = [e^\\prime]_\\times P^\\prime P^+$, where $e^\\prime=P^\\prime C$, with $PC=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_F(C, P0, P1):\n",
    "    C = eucl2homo(C)\n",
    "    return skew(P1 @ C) @ P1 @ np.linalg.pinv(P0)\n",
    "\n",
    "# given two 2D points, print the line equation\n",
    "def line_equation(pt1, pt2):\n",
    "    m = (pt2[1] - pt1[1]) / (pt2[0] - pt1[0])\n",
    "    k = (pt1[1] * pt2[0] - pt2[1] * pt1[0]) / (pt2[0] - pt1[0])\n",
    "    print(f'line equation : {m:.2f}x + {k:.2f} = y')\n",
    "\n",
    "# point size\n",
    "size = 5\n",
    "\n",
    "# create two cameras\n",
    "cameraA = Camera(Ry(np.pi/2)@Rz(-np.pi/2)@Ry(np.pi/4), np.array([2, 3, 1]), \"Cam1\", show_frame=False)\n",
    "cameraB = Camera(Ry(np.pi/2)@Rz(-np.pi/2)@Ry(-np.pi/9), np.array([1, -2, 1]), \"Cam2\", show_frame=False)\n",
    "\n",
    "# test point \n",
    "X = np.array([5, 2, 1.6])\n",
    "\n",
    "ptX = PointCloud(size=size)\n",
    "ptX.add_data([X, 'red']) # will not be plotted \n",
    "cameraA.capture(ptX)\n",
    "cameraB.capture(ptX)\n",
    "\n",
    "F = find_F(cameraA.center, cameraA.P, cameraB.P)\n",
    "\n",
    "# =========== x -> l ====================\n",
    "l = F @ eucl2homo(cameraA.image_pts[0])\n",
    "# =======================================\n",
    "    \n",
    "epiline = CameraLine(l, cameraB, color='red')\n",
    "line1 = Segment(cameraA.center, cameraB.center)\n",
    "line2 = Segment(cameraA.center, X, 'red')\n",
    "line3 = Segment(cameraB.center, X)\n",
    "\n",
    "# epipole and projected point on second image plane \n",
    "epipole1 = homo2eucl(cameraA.P @ eucl2homo(cameraB.center))\n",
    "epipole2 = homo2eucl(cameraB.P @ eucl2homo(cameraA.center))\n",
    "Xproj1 = homo2eucl(cameraA.P @ eucl2homo(X))\n",
    "Xproj2 = homo2eucl(cameraB.P @ eucl2homo(X))\n",
    "pt_epipole1 = CameraPoint(epipole1, cameraA, size=size)\n",
    "pt_epipole2 = CameraPoint(epipole2, cameraB, size=size)\n",
    "pt_Xproj1 = CameraPoint(Xproj1, cameraA, size=size)\n",
    "pt_Xproj2 = CameraPoint(Xproj2, cameraB, size=size)\n",
    "\n",
    "# verify fundemental matrix properties \n",
    "\n",
    "print(\"Verify fundemental matrix properties\")\n",
    "print(\"-\"*40)\n",
    "print(\"point correspondance :\", np.allclose(eucl2homo(cameraB.image_pts[0])[None, :] @ F @ eucl2homo(cameraA.image_pts[0]), 0))\n",
    "print(\"l\\'=Fx :\", \"demonstrate using the graph.\")\n",
    "print(\"Fe = 0 and F^T e\\' = 0 :\", np.allclose(F @ eucl2homo(epipole1), 0), \",\", np.allclose(F.T @ eucl2homo(epipole2), 0))\n",
    "print(\"-\"*40)\n",
    "\n",
    "# add name tags\n",
    "text = Text([pt_epipole1.data, pt_epipole2.data, pt_Xproj1.data, pt_Xproj2.data, X, 2*pt_Xproj2.data-pt_epipole2.data], \n",
    "            ['e', 'e\\'', 'x', 'x\\'', 'X', 'l\\''])\n",
    "\n",
    "FIG = Show([cameraA, cameraB, ptX, epiline, line1, line2, line3, pt_epipole1, pt_epipole2, pt_Xproj1, pt_Xproj2, text], world=True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The essential matrix $E$\n",
    "**Derivation** <br>\n",
    "Consider a pair of cameras: $P = [I|0]$ and $P^\\prime = [R | t]$. <br>\n",
    "The fundemental matrix of this pair is the essential matrix. \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    PC &= 0 \\Rightarrow C = \\left[ {\\begin{array}{c} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{array}}\\right] \\\\\n",
    "    e^\\prime &= P^\\prime C = t \\\\\n",
    "    P^+ &= \\left[\\begin{array}{c} I \\\\ \\hline 0 \\end{array}\\right] \\\\ \n",
    "    E &= [e^\\prime]_\\times P^\\prime P^+ = [t]_\\times R = R [R^T t]_\\times\n",
    "    \\\\ \\\\ \n",
    "    \\hat{x}^{\\prime T} E \\hat{x} &= 0 \\ \\text{, where } \\hat{x} \\text{ is in the camera coordinate frame.}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**How to find the relative $R$ and $t$ between two cameras if their projection matrices are not in the form shown above?**<br>\n",
    "Assume camera 1 has $pose1$ and $center1$, camera 2 has $pose2$ and $center2$. ($pose$ is the rotation matrix that transform the world coordinate to camera coordinate, $center$ is the camera center represented in world coordinate frame).\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    X_{world} &= Center + Pose X_{cam} \\Rightarrow X_{cam} = Pose^T (X_{world} - Center) \\\\\n",
    "    X_{world} &= Pose^{(1)} X_{cam}^{(1)} + Center^{(1)} \\\\\n",
    "    &= Pose^{(2)} X_{cam}^{(2)} + Center^{(2)} \\\\\n",
    "    X_{cam}^{(2)} &= Pose^{(2)T}(X_{world} - Center^{(2)}) \\\\\n",
    "    &= Pose^{(2)T}(Pose^{(1)} X_{cam}^{(1)} + Center^{(1)} - Center^{(2)}) \\\\\n",
    "    &= Pose^{(2)T}Pose^{(1)} X_{cam}^{(1)} + Pose^{(2)T}(Center^{(1)} - Center^{(2)}) \\\\\n",
    "    &= R X_{cam}^{(1)} + t \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We use $X$ and $X^\\prime$ to represent $X_{cam}^{(1)}$ and $X_{cam}^{(2)}$ for convenience. <br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    X^\\prime &= R X + t \\\\\n",
    "    [t]_\\times X^\\prime &= [t]_\\times R X + [t]_\\times t = [t]_\\times R X \\\\\n",
    "    X^{\\prime T} [t]_\\times X^\\prime &= 0 = X^{\\prime T} [t]_\\times R X \\\\\n",
    "    \\Rightarrow X^{\\prime T} [t]_\\times R X &= X^{\\prime T} E X = 0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two cameras\n",
    "cameraA = Camera(Ry(np.pi/2)@Rz(-np.pi/2)@Ry(np.pi/4), np.array([2, 3, 1]), \"Cam1\")\n",
    "cameraB = Camera(Ry(np.pi/2)@Rz(-np.pi/2)@Ry(-np.pi/9), np.array([1, -2, 2]), \"Cam2\")\n",
    "\n",
    "# define observation data \n",
    "pt1 = np.array([4, 1, 1])\n",
    "pts = PointCloud()\n",
    "pts.add_data([pt1, 'red'])\n",
    "cameraA.capture(pts)\n",
    "cameraB.capture(pts)\n",
    "\n",
    "X = cameraA.camera_pts[0]\n",
    "\n",
    "R = cameraB.pose.T @ cameraA.pose\n",
    "t = cameraB.pose.T @ (cameraA.center - cameraB.center)\n",
    "Xprime = cameraB.camera_pts[0]\n",
    "print('X\\' = RX + t :', np.allclose(R @ X + t, Xprime))\n",
    "print('T x X\\' = T x RX + T x T :', np.allclose(skew(t) @ Xprime, skew(t) @ R @ X))\n",
    "print('X\\'.(T x X\\') = X\\'.(T x RX) = 0 :', np.logical_and(\n",
    "    np.allclose(np.dot(Xprime, skew(t) @ Xprime), np.dot(Xprime, skew(t) @ R @ X)), \n",
    "    np.allclose(np.dot(Xprime, skew(t) @ R @ X), 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps of reconstruction: \n",
    "$$ \n",
    "    \\{x_i \\leftrightarrow x_i^\\prime\\} \\Rightarrow F \\Rightarrow P, P^\\prime \\Rightarrow X_i\n",
    "$$\n",
    "1. Pixel correspondence in two images\n",
    "2. Estimating the fundemental matrix\n",
    "3. Estimating the camera matrices \n",
    "4. Finding the 3D location of matched pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of $F$\n",
    "1. Solve $x^{\\prime T} F x = 0$ \n",
    "$$\n",
    "    Af = \\left[\\begin{array}{c}\n",
    "        x_1^{\\prime} x_1 & x_1^{\\prime} y_1 & x_1^{\\prime} & \n",
    "        y_1^{\\prime} x_1 & y_1^{\\prime} y_1 & y_1^{\\prime} & \n",
    "        x_1 & y_1 & 1 \\\\ \n",
    "        \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "        x_n^{\\prime} x_n & x_n^{\\prime} y_n & x_n^{\\prime} & \n",
    "        y_n^{\\prime} x_n & y_n^{\\prime} y_n & y_n^{\\prime} & \n",
    "        x_n & y_n & 1 \n",
    "    \\end{array}\\right] f = 0\n",
    "$$\n",
    "\n",
    "2. Singularity constraint: F has to be singular \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    &minimize \\ \\ \\lVert Af^\\prime \\rVert \\ \\ s.t. \\ \\ \\lVert f^\\prime \\rVert =1 \\\\\n",
    "    &then \\\\\n",
    "    &minimize \\ \\ \\lVert F - F^\\prime \\rVert \\ \\ s.t. \\ \\ det(F) = 0 \\\\ \n",
    "    \\\\ \n",
    "    F^\\prime &= U \\left[{\\begin{array}{c} \n",
    "        \\sigma_1 &          &          \\\\\n",
    "                 & \\sigma_2 &          \\\\\n",
    "                 &          & \\sigma_3 \n",
    "    \\end{array}}\\right] V^T \\\\\n",
    "    \\Rightarrow F &= U \\left[{\\begin{array}{c} \n",
    "        \\sigma_1 &          &          \\\\\n",
    "                 & \\sigma_2 &          \\\\\n",
    "                 &          & 0 \n",
    "    \\end{array}}\\right] V^T \\\\\n",
    "\\end{aligned}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image point correspondence\n",
    "x = camera1.image_pts \n",
    "xprime = camera2.image_pts\n",
    "\n",
    "# add tiny noise to avoid perfect point correspondence\n",
    "x = x + np.random.randn(*x.shape) * 1e-8\n",
    "\n",
    "print(f\"Point correspondence x: {x.shape}, x\\': {xprime.shape}\")\n",
    "\n",
    "def build_A(x1, x2):\n",
    "    assert x1.shape == x2.shape\n",
    "    x1 = eucl2homo(x1)\n",
    "    x2 = eucl2homo(x2)\n",
    "    N = x1.shape[0]\n",
    "    A = np.zeros((N, 9))\n",
    "    for i in range(N):\n",
    "        A[i, :] = np.outer(x1[i], x2[i]).ravel()\n",
    "    return A\n",
    "\n",
    "def solve_Ax_equal_0(A):\n",
    "    return np.linalg.svd(A)[2][-1, :]\n",
    "\n",
    "def force_singular(Fprime):\n",
    "    U, S, Vt = np.linalg.svd(Fprime)\n",
    "    S[-1] = 0\n",
    "    return U @ np.diag(S) @ Vt\n",
    "\n",
    "# build matrix \"A\"\n",
    "A = build_A(x, xprime)\n",
    "\n",
    "# find fundemental matrix F\n",
    "Fprime = solve_Ax_equal_0(A).reshape(3, 3)\n",
    "F = force_singular(Fprime)\n",
    "\n",
    "# analysis\n",
    "print(f\"Rank(F\\') = {np.linalg.matrix_rank(Fprime)}\")\n",
    "print(f\"Rank(F) = {np.linalg.matrix_rank(F)}\")\n",
    "estimation_error = np.mean(np.abs(np.sum(eucl2homo(xprime) * (eucl2homo(x) @ F.T ), axis=1)))\n",
    "print(f\"Estimation error: mean(abs(x\\'Fx - 0)) = {estimation_error:.5f}\")\n",
    "\n",
    "# ground truth F\n",
    "F_groundtruth = find_F(camera1.center, camera1.P, camera2.P)\n",
    "estimation_error = np.mean(np.abs(np.sum(eucl2homo(xprime) * (eucl2homo(x) @ F_groundtruth.T ), axis=1)))\n",
    "print(f\"Ground truth error: mean(abs(x\\'Fx - 0)) = {estimation_error:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find $P$ and $P^\\prime$ from $F$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- R. Hartley, A. Zisserman Multiple View Geometry in Computer Vision 2nd Ed., Cambridge Univ. Press, 2004"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
